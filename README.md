**American Sign Language Hand Gesture Recognition**

American Sign Language (ASL) is a complete, complex language that employs signs made by moving the
hands combined with facial expressions and postures of the body. It is the primary language of many
North Americans who are deaf and is one of several communication options used by people who are deaf or
hard-of-hearing.

The hand gestures representing English alphabet are shown below. This project focuses on classifying a subset
of these hand gesture images using convolutional neural networks. Specifically, given an image of a hand
showing one of the letters A-I, I want to detect which letter is being represented.

In this project, I build two models: (1) CNN model from scratch and (2) CNN model with transfer learning using AlexNet pretrained weights.
We see that the final model with transfer learning achieves a test accuracy of 93%.
